{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa44f1d3-f388-4e78-80fe-261cdfcc6a0f",
   "metadata": {},
   "source": [
    "## Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ccc5487-693b-403e-849e-6a8122600c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804d279-8312-4b4a-9c3a-4078f4968c01",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6347dc2-9a0e-4955-896f-d1b0d2fc6c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13818513</td>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13728867</td>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13681000</td>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13730747</td>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13728094</td>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           dialogue  \\\n",
       "0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1  13728867  Olivia: Who are you voting for in this electio...   \n",
       "2  13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4  13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "\n",
       "                                             summary  \n",
       "0  Amanda baked cookies and will bring Jerry some...  \n",
       "1  Olivia and Olivier are voting for liberals in ...  \n",
       "2  Kim may try the pomodoro technique recommended...  \n",
       "3  Edward thinks he is in love with Bella. Rachel...  \n",
       "4  Sam is confused, because he overheard Rick com...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (example, adjust path as needed)\n",
    "train_data = pd.read_csv(\"samsum-train.csv\")\n",
    "validation_data = pd.read_csv(\"samsum-validation.csv\")\n",
    "\n",
    "# Display a sample\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d61ece7-8a0f-4e5a-888a-bcd3e3170ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(n=4000,random_state=42).reset_index(drop=True)\n",
    "validation_data = validation_data.sample(n=500, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad08413-6722-4129-b383-14d87b94f933",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe824ce-5100-438e-99e3-350570039cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13811908</td>\n",
       "      <td>violet: hi! i came across this austin's articl...</td>\n",
       "      <td>violet sent claire austin's article.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13716431</td>\n",
       "      <td>pat: so does anyone know when the stream is go...</td>\n",
       "      <td>pat and lou are waiting for the stream but kev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13810214</td>\n",
       "      <td>jane:  jane: whaddya think? shona: this ur tin...</td>\n",
       "      <td>jane is updating her tinder profile tonight an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13729823</td>\n",
       "      <td>adam: do u have a map of paris? tom: yes, why?...</td>\n",
       "      <td>tom has a map of paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13681400</td>\n",
       "      <td>frank: hi, how's the family? mike: great! sam'...</td>\n",
       "      <td>mike is happy, because sam's moved out. mike a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>13681041</td>\n",
       "      <td>barry: hello buddy michael: hey barry: do you ...</td>\n",
       "      <td>barry and michael will watch football instead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>13818705</td>\n",
       "      <td>karen: hey lisa. larissa and me have recently ...</td>\n",
       "      <td>karen and larissa moved to belgium and ask lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>13821859</td>\n",
       "      <td>miles: hey, guys, i'm so sorry, but i missed t...</td>\n",
       "      <td>miles has missed the bus, so he may be 15 minu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>13812716</td>\n",
       "      <td>emma: did you finish the book i gave you? liam...</td>\n",
       "      <td>emma gave \"the first fifteen lives of harry au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>13717021</td>\n",
       "      <td>jenna: dudes, were we supposed to read the who...</td>\n",
       "      <td>jenna, hannah and denis should read 40 pages f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           dialogue  \\\n",
       "0     13811908  violet: hi! i came across this austin's articl...   \n",
       "1     13716431  pat: so does anyone know when the stream is go...   \n",
       "2     13810214  jane:  jane: whaddya think? shona: this ur tin...   \n",
       "3     13729823  adam: do u have a map of paris? tom: yes, why?...   \n",
       "4     13681400  frank: hi, how's the family? mike: great! sam'...   \n",
       "...        ...                                                ...   \n",
       "3995  13681041  barry: hello buddy michael: hey barry: do you ...   \n",
       "3996  13818705  karen: hey lisa. larissa and me have recently ...   \n",
       "3997  13821859  miles: hey, guys, i'm so sorry, but i missed t...   \n",
       "3998  13812716  emma: did you finish the book i gave you? liam...   \n",
       "3999  13717021  jenna: dudes, were we supposed to read the who...   \n",
       "\n",
       "                                                summary  \n",
       "0                  violet sent claire austin's article.  \n",
       "1     pat and lou are waiting for the stream but kev...  \n",
       "2     jane is updating her tinder profile tonight an...  \n",
       "3                               tom has a map of paris.  \n",
       "4     mike is happy, because sam's moved out. mike a...  \n",
       "...                                                 ...  \n",
       "3995  barry and michael will watch football instead ...  \n",
       "3996  karen and larissa moved to belgium and ask lis...  \n",
       "3997  miles has missed the bus, so he may be 15 minu...  \n",
       "3998  emma gave \"the first fifteen lives of harry au...  \n",
       "3999  jenna, hannah and denis should read 40 pages f...  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text by removing unwanted characters\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\r\\n', ' ', text)  # Remove carriage returns and line breaks\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove any XML tags\n",
    "    text = text.strip().lower()  # Strip and convert to lower case\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to dialogue and summary columns\n",
    "train_data['dialogue'] = train_data['dialogue'].apply(clean_text)\n",
    "train_data['summary'] = train_data['summary'].apply(clean_text)\n",
    "\n",
    "validation_data['dialogue'] = validation_data['dialogue'].apply(clean_text)\n",
    "validation_data['summary'] = validation_data['summary'].apply(clean_text)\n",
    "\n",
    "\n",
    "# Display a sample after cleaning\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336fae77-684b-4d68-b730-2e554bda79ff",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69b7fb8-c774-4fe4-ad8d-e42cd514d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040 90\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# pick your model (replace with the one you are using, e.g., \"facebook/bart-base\" or \"t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "input_max_len = max(len(tokenizer.encode(text, truncation=True)) for text in train_data['dialogue'])\n",
    "output_max_len = max(len(tokenizer.encode(text, truncation=True)) for text in train_data['summary'])\n",
    "\n",
    "print(input_max_len, output_max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab251489-0be7-464f-b3df-56cf07b541cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\syed sarafeena ali\\anaconda\\lib\\site-packages (0.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\SYED SARAFEENA ALI\\anaconda\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!\"C:\\Users\\SYED SARAFEENA ALI\\anaconda\\python.exe\" -m pip install sentencepiece --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49622ff-923c-4a52-b020-18e2b8daeb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecd9a27-890f-4795-8a55-f10f147e3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for tokenization\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the dialogue and summary\n",
    "    inputs = tokenizer(examples[\"dialogue\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    targets = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing\n",
    "train_dataset = train_data.apply(preprocess_function, axis=1)\n",
    "val_dataset = validation_data.apply(preprocess_function, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4057e61-c1b6-444b-a494-04e2382ecc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [25208, 10, 7102, 55, 3, 23, 764, 640, 48, 403, 17, 77, 31, 7, 1108, 11, 3, 23, 816, 24, 25, 429, 253, 34, 1477, 25208, 10, 3, 7997, 15, 10, 7102, 55, 3, 10, 61, 2049, 6, 68, 3, 23, 31, 162, 641, 608, 34, 5, 3, 10, 61, 3, 7997, 15, 10, 68, 2049, 21, 1631, 81, 140, 3, 10, 61, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [25208, 1622, 3, 7997, 15, 403, 17, 77, 31, 7, 1108, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fed318-7215-4b5b-a639-25505c54d04f",
   "metadata": {},
   "source": [
    "## Fine Tuning The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70840b7a-7aa3-460a-87fb-33a290539770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluation in c:\\users\\syed sarafeena ali\\anaconda\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\syed sarafeena ali\\anaconda\\lib\\site-packages (from evaluation) (2.1.3)\n",
      "Requirement already satisfied: glog in c:\\users\\syed sarafeena ali\\anaconda\\lib\\site-packages (from evaluation) (0.3.1)\n",
      "Requirement already satisfied: python-gflags>=3.1 in c:\\users\\syed sarafeena ali\\anaconda\\lib\\site-packages (from glog->evaluation) (3.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\syed sarafeena ali\\appdata\\roaming\\python\\python313\\site-packages (from glog->evaluation) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\SYED SARAFEENA ALI\\anaconda\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!\"C:\\Users\\SYED SARAFEENA ALI\\anaconda\\python.exe\" -m pip install evaluation --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86bbe0-e543-4504-be90-b5ce56e0d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "\n",
    "# Load model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # output directory\n",
    "    overwrite_output_dir=True,  # overwrite old checkpoints\n",
    "    num_train_epochs=6,  # training epochs\n",
    "    per_device_train_batch_size=8,  # batch size for training\n",
    "    per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "    warmup_steps=500,  # warmup steps\n",
    "    weight_decay=0.01,  # weight decay\n",
    "    logging_dir=\"./logs\",  # log directory\n",
    "    logging_steps=50,  # log every 50 steps\n",
    "    save_steps=500,  # save every 500 steps\n",
    "    eval_strategy=\"epoch\",  # Corrected parameter for evaluation strategy\n",
    "    save_total_limit=2,  # keep only last 2 checkpoints\n",
    ")\n",
    "\n",
    "# Setup Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fe028-21b8-4661-ae2a-e07ed943a59b",
   "metadata": {},
   "source": [
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f00777-157a-4b8b-83fe-f4e181a78928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_summary_model\\\\tokenizer_config.json',\n",
       " './saved_summary_model\\\\special_tokens_map.json',\n",
       " './saved_summary_model\\\\spiece.model',\n",
       " './saved_summary_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./saved_summary_model\")\n",
    "tokenizer.save_pretrained(\"./saved_summary_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca580f16-1a6d-4961-a8a2-7386858e1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./saved_summary_model\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./saved_summary_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e61755f-92d7-4afb-9d1c-64d8f48e7460",
   "metadata": {},
   "source": [
    "## Summarization System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49b7d716-b173-48ed-a870-271100565825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is on the correct device (GPU if available)\n",
    "device = model.device  # Get the device the model is on\n",
    "\n",
    "def summarize_dialogue(dialogue):\n",
    "    dialogue = clean_text(dialogue)  # Assuming clean_text is defined\n",
    "    inputs = tokenizer(dialogue, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    \n",
    "    # Move input tensors to the same device as the model\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_length=150,  \n",
    "        num_beams=4, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the generated summary\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e02bc2a5-a63d-4ff0-a394-6d0ea0fc4952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: : hey claire! i was reading an article about austin and thought you might find it interesting! violet: it's about the current trends in urban development and how cities are planning for the future. violet: it was really interesting though, especially the part about sustainable architecture in cities.\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample input\n",
    "sample_dialogue = \"\"\"\n",
    "Violet: Hey Claire! I was reading an article about Austin and thought you might find it interesting! \n",
    "Violet: It's about the current trends in urban development and how cities are planning for the future.\n",
    "Violet: Here, let me share the link: <file_other>\n",
    "Claire: Oh wow, that sounds like an insightful read. But I've actually already read that one last week. \n",
    "Claire: It was really interesting though, especially the part about sustainable architecture in cities. \n",
    "Claire: You know, I've been following these urban planning discussions for a while now.\n",
    "Violet: Oh, I didnâ€™t know that! Well, Iâ€™ll look for something else then, maybe something about eco-friendly cities or tech innovations.\n",
    "Claire: That would be awesome! Let me know if you find something cool.\n",
    "Violet: Sure, Iâ€™ll keep you posted. Thanks for the feedback!\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(sample_dialogue)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c37410aa-2163-4831-b3b1-7fdead73ba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: sarah: hey sarah, have you seen the latest tech gadget reviews? john: it's supposed to have amazing health tracking features. john: it tracks heart rate, blood oxygen levels, sleep patterns, and even stress levels! sarah: that sounds really interesting! john: yeah, me too! there are also some new smartphones coming out with even better cameras.\n"
     ]
    }
   ],
   "source": [
    "# Test with a dialogue on a different topic\n",
    "sample_dialogue = \"\"\"\n",
    "John: Hey Sarah, have you seen the latest tech gadget reviews? I found this new smartwatch that's supposed to have amazing health tracking features.\n",
    "John: It tracks heart rate, blood oxygen levels, sleep patterns, and even stress levels! It sounds like something right up your alley. \n",
    "Sarah: That sounds really interesting! But Iâ€™ve been trying to cut down on tech distractions. Iâ€™ve heard these devices can be really overwhelming sometimes.\n",
    "Sarah: I do think itâ€™s cool that they can track so many health metrics though. Iâ€™m curious how accurate they really are.\n",
    "John: Yeah, me too! There are also some new smartphones coming out with even better cameras and longer battery life. The new flagship model from XYZ brand has some insane specs.\n",
    "Sarah: Ooh, I havenâ€™t kept up with phones recently, but Iâ€™ve heard the camera quality is getting ridiculously good. Itâ€™s almost like a professional camera in your pocket now!\n",
    "Sarah: Still, I feel like Iâ€™m fine with my current phone for now. I donâ€™t really feel the need to upgrade unless something really groundbreaking comes out.\n",
    "John: Totally understand that. Itâ€™s the same with me. But I think the battery life improvements are enough to make me consider it. I hate running out of battery when Iâ€™m out and about.\n",
    "Sarah: Thatâ€™s fair! Iâ€™m always worried about battery life too. Honestly, I think phones should last at least two full days on a single charge by now.\n",
    "John: I agree! Itâ€™s so annoying when your phone dies in the middle of the day. I wonder if weâ€™ll ever get to a point where we donâ€™t have to charge our phones every day.\n",
    "Sarah: That would be amazing! I think as tech improves, battery tech might also catch up. Letâ€™s hope the next generation of phones can last longer!\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(sample_dialogue)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c8fa70c-0dd9-4c78-bba9-ae2d0f79969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: ipcc report reveals alarming global temperature rises. if global temperatures increase by more than 1.5Â°c, we could face irreversible damage to ecosystems, agriculture, and water supply. experts: if global temperatures increase by more than 1.5Â°c, we could face irreversible damage to ecosystems, agriculture, and water supply.\n"
     ]
    }
   ],
   "source": [
    "# Test with a dialogue on a current news topic\n",
    "sample_dialogue = \"\"\"\n",
    "Reporter: In today's news, the latest climate change report reveals alarming global temperature rises. According to the Intergovernmental Panel on Climate Change (IPCC), the Earthâ€™s temperature is on track to rise by 1.5Â°C within the next two decades.\n",
    "Reporter: This is expected to lead to more frequent and severe heatwaves, flooding, and extreme weather events. Coastal cities are at particular risk due to rising sea levels.\n",
    "Expert: The report emphasizes that immediate action is needed to prevent catastrophic consequences. We need to significantly reduce carbon emissions and transition to renewable energy sources.\n",
    "Expert: If global temperatures increase by more than 1.5Â°C, we could face irreversible damage to ecosystems, agriculture, and water supply. It will have a devastating impact on biodiversity as well.\n",
    "Reporter: The IPCC also stresses the importance of individual action. Governments must set stronger policies, but individuals can help by reducing waste, conserving water, and supporting green initiatives.\n",
    "Expert: It's not just about the big changes; small actions like using public transportation, reducing meat consumption, and recycling can collectively make a significant difference.\n",
    "Reporter: With the next UN Climate Summit coming up next month, world leaders will need to prioritize climate action. The stakes have never been higher for our planetâ€™s future.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_dialogue(sample_dialogue)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd7222-5412-4070-a8bd-d2a817ed40c9",
   "metadata": {},
   "source": [
    "## Download Mode To Your Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "269a16da-0339-4218-aa0f-d6610e1d8f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SYED SARAFEENA ALI\\\\OneDrive\\\\Desktop\\\\NLP - TEXT SUMMARIZATION\\\\saved_summary_model.zip'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to the directory containing the fine-tuned model\n",
    "model_dir = \"./saved_summary_model\"\n",
    "\n",
    "# Output zip file path\n",
    "output_zip_path = \"saved_summary_model.zip\"\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(base_name=\"saved_summary_model\", format=\"zip\", root_dir=model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1abb5d91-846c-4953-bf2c-1f2f34c6e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='saved_summary_model.zip' target='_blank'>saved_summary_model.zip</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\SYED SARAFEENA ALI\\OneDrive\\Desktop\\NLP - TEXT SUMMARIZATION\\saved_summary_model.zip"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Display a download link\n",
    "FileLink(output_zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52c384-68cc-49b1-b285-eaff98704291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
